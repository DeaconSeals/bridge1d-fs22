{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e687ec",
   "metadata": {},
   "source": [
    "# Assignment 1c Notebook: Multi-Objective EA\n",
    "This notebook is part of Assignment 1c, which will guide you through half of this two-part assignment: building a multi-objective EA (MOEA). This assignment builds on the EA code you wrote in Assignment 1b; therefore, if this is the first notebook you're filling out for Assignment 1c, you should copy over the following files:\n",
    "* 1a_notebook.ipynb\n",
    "* 1b_notebook.ipynb\n",
    "* base_evolution.py\n",
    "* bridge_population_evaluation.py\n",
    "* linear_genotype.py\n",
    "* selection.py\n",
    "\n",
    "\n",
    "*Be careful* to not copy over functions relating to the provided fitness functions or bridge structures (files you shouldn't have modified anyways). We may have changed those and we want you to have the versions that were provided with this repo.\n",
    "\n",
    "As usual, be sure to **read all of this notebook** and you can start by executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure this notebook to automatically reload modules as they're modified\n",
    "# https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # hopefully stop any pedantic warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "print('The first cell has been executed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc845e8",
   "metadata": {},
   "source": [
    "## Multi-Objective Fitness Evaluations\n",
    "In a traditional MOEA implementation like the Non-dominated Sorting Genetic Algorithm II [(NSGA-II)](https://ieeexplore.ieee.org/abstract/document/996017?casa_token=sIy9DHU74qAAAAAA:f9M0Nu6WrHIswdRILFlqhxUqW-rK1nfke65Xw88A1JNX5TaaXZAL76yrC3L8WncdUlrDi25Y7Zo), individuals in a population are assessed by multiple objectives, assigned a score for each objective, and are then sorted into levels of non-domination (more on that later) during parent and survival selection. In a traditional MOEA implementation, you might write a multi-objective version of k-tournament that samples k individuals from the population and selects the winner as the individual who is on the Pareto front from those k individuals. This formulation thus doesn't use a single-value notion of fitness as your existing k-tournament implementations do. This works because k-tournament selection is a rank-based algorithm, only relying on relative comparisons between individuals (more fit, less fit, or equally-fit). However, not all selection algorithms work this way: for example, fitness-proportional selection requires numeric values that are proportional to fitness.\n",
    "\n",
    "To enable the re-use of your existing selection algorithms, we propose a novel MOEA implementation that assigns individuals in a population a singular fitness value based on their level of non-domination. This behaves in a functionally equivalent manner to the rank-based selection algorithms used in traditional MOEA implementations.\n",
    "\n",
    "In your MOEA for this assignment, you will do the following:\n",
    "* Evaluate new members in a population to assign objective scores\n",
    "* Construct a domination table for *all* individuals in the population\n",
    "* Sort the population into levels of non-domination where level 0 is the Pareto front\n",
    "* To each individual in the population, assign a representative fitness that is inversely proportional to their level of non-domination \n",
    " - i.e., `num_levels - my_level`\n",
    "\n",
    "To accomplish this, you'll implement three functions:\n",
    "1. `multi_objective_population_evaluation` - which assigns objective score to new population members after initialization\n",
    "2. `dominates` - which takes individuals `A` and `B` as  inputs and returns `True` if `A` dominates `B`\n",
    "3. `non_domination_sort` - which sorts the population into levels of non-domination and assigns a representative fitness.\n",
    "\n",
    "First, let's start by showing an example of the new fitness function `multi_objective_simulation`. This behaves the same as `basic_simulation`, except the first returned value is a list of fitness values (one for each objective)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b431de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selection import *\n",
    "from snake_eyes import read_config\n",
    "from linear_genotype import LinearGenotype\n",
    "from bridge_fitness import multi_objective_simulation, plot_bridge\n",
    "\n",
    "config = read_config('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "test_solution = LinearGenotype()\n",
    "test_solution.random_initialization(**config['initialization_kwargs'])\n",
    "\n",
    "test_solution.objectives, test_solution.bridge = multi_objective_simulation(test_solution.gene, **config['fitness_kwargs'])\n",
    "\n",
    "print(f\"The solution's objective scores are:\")\n",
    "for objective in test_solution.objectives:\n",
    "    print(f\"{objective:,}\")\n",
    "plot_bridge(test_solution.bridge)\n",
    "\n",
    "del config, test_solution # to prevent haphazard copypasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab9690",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "For the green and yellow deliverables in this assignment, the objectives considered are as follows:\n",
    " 1.  Weight - The amount of weight a bridge can support before failing or a negative value if the bridge cannot support its own weight (the standard definition of fitness we've been using throughout this assignment series).\n",
    " 2.  Material - The negated total length of material used to construct the bridge. This metric reflects the cost in materials to build the bridge, though we negate this value so you can consistently consider the higher value as better across all your objectives.\n",
    "\n",
    "For one of the red (bonus) deliverables, you'll also consider a third objective:\n",
    "\n",
    " 3.  Height - Highest y-value in the connected bridge. (See assignment description document for more info.)\n",
    "\n",
    "Now that you've seen an example of calling the fitness function in a new way, complete the `multi_objective_population_evaluation` function in `bridge_population_evaluation.py`, which takes as input a population and fitness_kwargs dictionary and populates the `objectives` and `bridge` member variables of all individuals in the population. It should look fairly similar to your `basic_population_evaluation` function, but it will call `multi_objective_simulation` and will not assign to the fitness member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6096ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from bridge_population_evaluation import multi_objective_population_evaluation\n",
    "\n",
    "config = read_config('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "example_population = LinearGenotype.initialization(10, **config['initialization_kwargs'])\n",
    "# Note explicitly initializing to None is unnecessary in general\n",
    "# We only do it here to test that you've actually set these values\n",
    "for individual in example_population:\n",
    "    individual.objectives = None\n",
    "\n",
    "# calling your function to test things out\n",
    "multi_objective_population_evaluation(example_population, **config['fitness_kwargs'])\n",
    "unassigned = len([individual.objectives for individual in example_population if individual.objectives is None])\n",
    "print(f'Individuals with unassigned objectives: {unassigned}')\n",
    "if unassigned == 0:\n",
    "    weights = [individual.objectives[0] for individual in example_population]\n",
    "    print(f'Best weight value: {max(weights):,}')\n",
    "    print(f'Average weight value: {statistics.mean(weights):,}')\n",
    "    materials = [individual.objectives[1] for individual in example_population]\n",
    "    print(f'Best material value: {max(materials):,}')\n",
    "    print(f'Average material value: {statistics.mean(materials):,}')\n",
    "\n",
    "del config, example_population, unassigned, evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce10b5",
   "metadata": {},
   "source": [
    "## Multi-Objective Domination\n",
    "As discussed in the course lectures, a prevalent way to assess solutions in an MOEA is to determine whether or not a solution *dominates* another solution in the population. Recall from the lecture that an individual `A` is said to dominate an individual `B` if and only if:\n",
    "* `A` is no worse than `B` in all objectives *AND*\n",
    "* `A` is strictly better than `B` in at least one objective\n",
    "\n",
    "In `domination.py`, implement the function `dominates` that compares the `objectives` member variables of the input individuals returns `True` if `A` dominates `B` and `False` otherwise.\n",
    "\n",
    "To evaluate your implementation of the `dominates` function, we're going to compare against the model answer from Question 11 of the second exam from Fall 2020 [(link here)](http://bonsai.auburn.edu/dtauritz/courses/ec/intro/2020fall/IntroECfs2020exam2key.pdf). The output generated by executing the following cell should match the domination table from part (a) of that problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad489db5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from domination import dominates\n",
    "\n",
    "objective_scores = [[8,2],\n",
    "                   [4,1],\n",
    "                   [2,3],\n",
    "                   [1,2],\n",
    "                   [9,1],\n",
    "                   [4,7],\n",
    "                   [2,5],\n",
    "                   [1,3],\n",
    "                   [10,7],\n",
    "                   [5,5]]\n",
    "expectation = [[2, 4],\n",
    "              [],\n",
    "              [4,8],\n",
    "              [],\n",
    "              [2],\n",
    "              [2,3,4,7,8],\n",
    "              [3,4,8],\n",
    "              [4],\n",
    "              [1,2,3,4,5,6,7,8,10],\n",
    "              [2,3,4,7,8]]\n",
    "\n",
    "config = read_config('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "example_population = LinearGenotype.initialization(len(objective_scores), **config['initialization_kwargs'])\n",
    "\n",
    "# assigning objectives this way for demo purposes only\n",
    "for index in range(len(objective_scores)):\n",
    "    example_population[index].objectives = objective_scores[index]\n",
    "\n",
    "print('ID\\t Dominates')\n",
    "\n",
    "# Note that this implementation of a domination table has some quirks so it matches the exam.\n",
    "# Advise caution if you copy this code later because you should probably modify it.\n",
    "for index in range(len(example_population)):\n",
    "    domination_list = list()\n",
    "    for opponent_index in range(len(example_population)):\n",
    "        if index == opponent_index:\n",
    "            continue\n",
    "        if dominates(example_population[index], example_population[opponent_index]):\n",
    "            domination_list.append(opponent_index+1)\n",
    "    print(f'{index+1}\\t{domination_list}', end='')\n",
    "    if domination_list != expectation[index]:\n",
    "        print(f'\\texpected {expectation[index]}')\n",
    "    else:\n",
    "        print()\n",
    "        \n",
    "del config, example_population, expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995b07bf",
   "metadata": {},
   "source": [
    "## Non-domination Sort\n",
    "With the `dominates` function implemented, you can now implement the `non_domination_sort` function (which is also in `domination.py`). This function takes as input a population and has three main steps:\n",
    "1. Calculate a domination lookup table (this is technically optional but provides a drastic speedup)\n",
    "2. Sort individuals into levels of non-domination with the algorithm performed in class and where level 0 is the Pareto front\n",
    "3. Assign each individual a representative fitness to their `fitness` member variable equal to the negation of its level of non-domination\n",
    "\n",
    "Note: you may implement additional helper functions to call within `non-domination_sort` so long as calling the `non_domination_sort` function produces the expected results.\n",
    "\n",
    "We'll evaluate your `non_domination_sort` implementation using the same exam question we used to evaluate `dominates`. As such, your algorithm should generate `fitness` values that describe a non-domination sort with a similar result to that in the model answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6861ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from domination import non_domination_sort\n",
    "\n",
    "config = read_config('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "example_population = LinearGenotype.initialization(len(objective_scores), **config['initialization_kwargs'])\n",
    "\n",
    "# assigning objectives this way for demo purposes only\n",
    "for index in range(len(objective_scores)):\n",
    "    example_population[index].objectives = objective_scores[index]\n",
    "\n",
    "# calling your function to test it out\n",
    "non_domination_sort(example_population, **config['EA_configs'])\n",
    "unassigned = len([individual.fitness for individual in example_population if individual.fitness is None])\n",
    "print(f'Individuals with unassigned fitness: {unassigned}')\n",
    "evaluations = len([individual.fitness for individual in example_population if individual.fitness is not None])\n",
    "print(f'Number of fitness evaluations performed: {evaluations}')\n",
    "\n",
    "fitnesses = set()\n",
    "\n",
    "for individual in example_population:\n",
    "    if individual.fitness is not None:\n",
    "        # truncate the fitness values in case you've implemented the YELLOW deliverable\n",
    "        individual.fitness = int(individual.fitness)\n",
    "    fitnesses.add(individual.fitness)\n",
    "\n",
    "fitnesses = sorted(list(fitnesses), reverse=True)\n",
    "print('\\nLevels of non-domination after adding all elements')\n",
    "for level_index in range(len(fitnesses)):\n",
    "    level = sorted([i+1 for i in range(len(example_population)) if example_population[i].fitness == fitnesses[level_index]])\n",
    "    print(f'level {level_index}: {level}')\n",
    "\n",
    "del config, example_population, unassigned, evaluations, fitnesses, objective_scores, level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ac4c0b",
   "metadata": {},
   "source": [
    "## Assembling the MOEA\n",
    "Now that you have `multi_objective_population_evaluation`, `dominates`, and `non_domination_sort` functions implemented, you can assemble your complete MOEA using the `BaseEvolutionPopulation` population class you implemented in Assignment 1b. There are, however, some small differences from a single-objective EA that we'll walk you through in the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f395f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_evolution import BaseEvolutionPopulation\n",
    "\n",
    "config = read_config('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "# full initialization of your EA\n",
    "exampleEA = BaseEvolutionPopulation(**config['EA_configs'], **config)\n",
    "multi_objective_population_evaluation(exampleEA.population, **config['fitness_kwargs'])\n",
    "\n",
    "# count evaluations for initial population\n",
    "exampleEA.evaluations = len(exampleEA.population)\n",
    "print(f'Number of fitness evaluations: {exampleEA.evaluations}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b018919",
   "metadata": {},
   "source": [
    "Until this point, the EA has gone as expected. We've read a config, initialized the EA, and evaluated the initial population. Recall, however, that the fitness evaluation only assigns objective scores that can't directly be used as single-value fitness in evolution. To calculate a single fitness value and evolve as usual, we have to add a call to the new `non_domination_sort` before entering child generation (and parent selection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort population and assign representative fitness\n",
    "non_domination_sort(exampleEA.population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3860c",
   "metadata": {},
   "source": [
    "Once `non_domination_sort` has been called, the EA can generate children. Once the children are evaluated for objective scores and have been added to the population, we need to re-sort the population and re-calculate representative fitness before entering survival selection. As a rule of thumb, you'll need to re-calculate representative fitness using `non_domination_sort` before each function call that utilizes a selection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e919b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate children\n",
    "children = exampleEA.generate_children()\n",
    "evaluate_population(children, **config['fitness_kwargs'])\n",
    "exampleEA.evaluations += len(children)\n",
    "print(f'Number of fitness evaluations: {exampleEA.evaluations}')\n",
    "\n",
    "# re-sort modified population and assign representative fitness\n",
    "non_domination_sort(exampleEA.population)\n",
    "\n",
    "# perform survival selection\n",
    "exampleEA.survival()\n",
    "\n",
    "del exampleEA, children # to prevent haphazard copypasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a607d",
   "metadata": {},
   "source": [
    "The calls to `non_domination_sort` are new additions to the EA cycle, but otherwise the MOEA cycle closely resembles that of previous assignments.\n",
    "\n",
    "Now that you've implemented the necessary functions and the MOEA cycle has been demonstrated, implement a single run of your MOEA that searches for 5,000 fitness evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f31a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_objective_EA_search(number_evaluations, config_filename):\n",
    "    # Parse the config and implement your EA here.\n",
    "    # Feel free to focus on implementation first and then return for data collection.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbe44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling your function\n",
    "print(multi_objective_EA_search(5000, './configs/green1c1_config.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d16d9",
   "metadata": {},
   "source": [
    "Now that you've tested an implementation of a single run, implement code to perform 30 runs of your MOEA search that each contain 5,000 evaluations. For each generation of each run, log the mean and best values for all objectives in the current population as well as the number of fitness evaluations performed so far (including the initial population). Also for each run, record the objective scores and bridges for all individuals in the Pareto front of the final generation. The bridges and objective scores will be used for analysis in your report.\n",
    "\n",
    "If you have attempted the YELLOW deliverable, you should record the diversity of the Pareto front from the final population of each run using a diversity metric of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15455a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_runs = 30\n",
    "number_evaluations = 5000\n",
    "\n",
    "# You can parse different configuration files here as necessary\n",
    "config = readConfig('./configs/green1c1_config.txt', globalVars=globals(), localVars=locals())\n",
    "\n",
    "# implement your multi-run experiment here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12bb45",
   "metadata": {},
   "source": [
    "## Report\n",
    "Comparing multi-objective performance is a [known-difficult problem](http://lopez-ibanez.eu/hypervolume) we consider to be outside the scope of this class. The required analysis and statistics requirements vary per deliverable. See the assignment description for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
